system_version: "1.0.0-frozen"
description: "Day 37 Snapshot - Auditable & Traceable Lineage"
hashing_utility: "utils.helper_functions.hash_object"

# -----------------------------------------------------------------------------
# GLOBAL METADATA REQUIREMENTS
# -----------------------------------------------------------------------------
# Every artifact produced by this system must carry these tags in its manifest
required_metadata:
  - dataset_hash      # The sha256 of the source text at time of generation
  - git_commit        # The code revision used to generate the artifact
  - config_snapshot   # The exact parameters used
  - artifact_hash     # The self-hash of the generated output

# -----------------------------------------------------------------------------
# ARTIFACT INVENTORY
# -----------------------------------------------------------------------------
artifacts:
  # --- LEVEL 1: DATA FOUNDATION (Immutable) ---
  raw_pdfs:
    path: "data/raw"
    storage: "dvc"
    type: "deterministic_source"
    description: "Original PDF ingestion inputs."
    regeneration_rule: "manual_ingest"
    
  processed_chunks:
    path: "data/processed/chunks"
    storage: "dvc"
    type: "deterministic_derived"
    description: "Cleaned, chunked, and deduplicated text."
    regeneration_rule: "pipelines/processing/extracting_and_chunking_pdfs.py"
    metadata_manifest: "data/versions/dataset_manifest.json" # Contains the Canonical Dataset Hash

  # --- LEVEL 2: RETRIEVAL INFRASTRUCTURE (Derived) ---
  faiss_index:
    path: "data/indexes/index_manifest.json"
    storage: "local_reproducible"
    type: "deterministic_derived"
    description: "Vector index linked to specific dataset hash and embedding model."
    regeneration_rule: "scripts/write_index_manifest.py"
    dependencies: 
      - "processed_chunks"
      - "pipelines/processing/build_embeddings_and_faiss.py"

  # --- LEVEL 3: LOGIC & PROMPTS (Versioned Code) ---
  rag_prompts:
    path: "pipelines/rag/answer.py"
    storage: "git"
    type: "code_logic"
    description: "Production prompt templates. Logic changes here invalidate downstream evaluations."
    hashing_strategy: "git_commit_hash"

  # --- LEVEL 4: TRAINING & EVALUATION DATA (Frozen Stochasticity) ---
  dataset_splits:
    path: "data/finetuning/splits/splits_manifest.json"
    storage: "local_reproducible"
    type: "frozen_stochastic"
    description: "Train/Val/Test splits with strict lineage to input files."
    regeneration_rule: "scripts/gen_splits.py"
    
  synthetic_qa_source:
    path: "data/finetuning" # section_qa.jsonl, etc.
    storage: "dvc"
    type: "frozen_stochastic"
    description: "Raw synthetic QA pairs generated by LLM."
    regeneration_rule: "scripts/generate_data/4_batch_synthesize.py"

  golden_answers:
    path: "pipelines/rag/answers.json"
    storage: "git"
    type: "frozen_stochastic"
    description: "Human-verified or Gold-Standard answers for regression testing."
    regeneration_rule: "manual_curation"

  # --- LEVEL 5: METRICS & LOGS (History) ---
  experiment_tracking:
    path: "mlflow.db"
    storage: "local"
    type: "log_history"
    description: "Immutable record of past runs."

# -----------------------------------------------------------------------------
# REGENERATION PROTOCOLS
# -----------------------------------------------------------------------------
protocols:
  on_code_change: "Re-run scripts/gen_splits.py to capture new git_commit in manifests."
  on_data_change: "Re-run scripts/compute_dataset_hash.py -> Re-run scripts/write_index_manifest.py"